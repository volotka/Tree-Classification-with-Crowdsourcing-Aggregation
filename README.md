# Tree Classification with Crowdsourcing Aggregation

## Описание проекта

Данный репозиторий посвящён задаче бинарной классификации изображений деревьев на два класса:

- **хвойные**
- **лиственные**

Ключевая особенность проекта — использование **краудсорсинговой разметки**, которая по своей природе является шумной и требует предварительной агрегации перед обучением модели.

Проект реализует полный end-to-end пайплайн:
1. анализ и агрегацию краудсорсинговых ответов;
2. сравнение различных методов агрегации;
3. формирование чистого обучающего датасета;
4. обучение и оценку глубокой нейросетевой модели для классификации изображений.

## Структура репозитория
.

├── aggregation_and_analysis.py / .ipynb

├── training_and_inference.py / .ipynb

└── README.md

## 1. aggregation_and_analysis

Файл отвечает за обработку и агрегацию краудсорсинговой разметки.

### Загрузка данных
- Чтение обучающих и валидационных файлов (`.tsv`, `.txt`);
- Сопоставление URL изображений и ответов исполнителей;
- Отдельная обработка заданий с «золотыми» метками (golden set).

### Оценка качества разметчиков
- Для оценки используются задания с эталонными ответами;
- Для каждого исполнителя рассчитывается точность (accuracy);
- Формируется таблица навыков разметчиков (`workers_skills`), используемая далее при агрегации.

### Методы агрегации ответов
Реализованы и сравниваются следующие подходы:

- **Majority Vote**  
  Простое голосование большинством.

- **David–Skene**  
  Вероятностная модель, оценивающая истинные метки и матрицы ошибок исполнителей.

- **Пользовательский алгоритм с учётом навыков**  
  Расширенный метод, учитывающий:
  - качество (skill) исполнителей,
  - сложность заданий,
  - адаптивные пороги принятия решения.

### Оценка качества агрегации
Методы агрегации сравниваются по метрикам:
- Accuracy
- Precision
- Recall
- F1-score

**Примечание:** так как для задачи критична метрика *Recall*, для дальнейшего обучения выбрана агрегация **David–Skene**, показавшая наилучший баланс качества.

### Результаты
- Агрегированные метки для всех заданий;
- Финальный датасет вида `(image_url, label)` для обучения модели.

---

## 2. training_and_inference

Файл содержит код для обучения модели и выполнения инференса.

### Подготовка данных
- Загрузка изображений по URL;
- Фильтрация повреждённых и недоступных изображений;
- Аугментация данных:
  - повороты (0°, 90°, 180°, 270°),
  - изменение яркости;
- Формирование обучающей и валидационной выборок.

### Dataset и DataLoader
- Кастомная реализация PyTorch `Dataset`;
- Стандартные трансформации `torchvision`:
  - изменение размера и кадрирование,
  - горизонтальные отражения,
  - нормализация по ImageNet.

### Архитектура модели
- Предобученная модель **Inception v3**;
- Замороженный backbone;
- Пользовательская полносвязная «голова» для бинарной классификации;
- Функция потерь: `BCEWithLogitsLoss`.

### Процесс обучения
- Оптимизатор: Adam;
- Планировщик скорости обучения: ReduceLROnPlateau;
- Сохранение чекпоинтов:
  - лучшая модель по Accuracy,
  - лучшая модель по ROC-AUC.

### Оценка качества модели
Используются следующие метрики:
- Accuracy
- Precision
- Recall
- F1-score
- ROC-AUC
- Матрица ошибок (Confusion Matrix)

Оценка проводится на валидационной выборке с использованием лучшего сохранённого чекпоинта.

---

## Используемые библиотеки

- pandas
- numpy
- scikit-learn
- PyTorch
- torchvision
- Pillow
- tqdm
- requests

---

## Итог

Проект демонстрирует практический подход к работе с краудсорсинговой разметкой в задачах компьютерного зрения.  
Показано, как оценка качества разметчиков и выбор метода агрегации напрямую влияют на итоговое качество нейросетевой модели, а также представлен воспроизводимый пример полного пайплайна — от сырых краудсорсинговых данных до обученной модели.
